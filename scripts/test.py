#!/usr/bin/env python3
"""
ThreeTaskDSPNet Testing Script

Detection + Surface + Depth 3íƒœìŠ¤í¬ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•˜ê³  ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.
"""

import os
import sys
import torch
import torch.nn.functional as F
import numpy as np
import cv2
import matplotlib.pyplot as plt
from PIL import Image
import argparse
from tqdm import tqdm

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ pathì— ì¶”ê°€
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

# ìƒˆë¡œìš´ êµ¬ì¡°ì— ë§ëŠ” import
from src.model import ThreeTaskDSPNet, load_pretrained_model
from utils.dataset import create_dataset, DETECTION_CLASSES, SURFACE_LABELS
from configs.config import Config


class ModelTester:
    """
    ëª¨ë¸ í…ŒìŠ¤íŠ¸ ë° ì‹œê°í™” í´ë˜ìŠ¤.
    """
    
    def __init__(self, checkpoint_path: str, device: str = 'auto'):
        """
        Initialize model tester.
        
        Args:
            checkpoint_path: Path to model checkpoint
            device: Device to run inference on
        """
        self.device = self._setup_device(device)
        self.model = self._load_model(checkpoint_path)
        
        # Surface í´ë˜ìŠ¤ ìƒ‰ìƒ ë§¤í•‘
        self.surface_colors = {
            0: [0, 0, 0],       # background - black
            1: [128, 64, 128],  # roadway - purple
            2: [244, 35, 232],  # sidewalk - pink  
            3: [70, 70, 70],    # other surface - gray
        }
        
        print(f"âœ… ModelTester ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"   ëª¨ë¸ íŒŒë¼ë¯¸í„°: {sum(p.numel() for p in self.model.parameters()):,}ê°œ")
        print(f"   ë””ë°”ì´ìŠ¤: {self.device}")
    
    def _setup_device(self, device: str) -> str:
        """Setup device."""
        if device == 'auto':
            device = "cuda" if torch.cuda.is_available() else "cpu"
        
        if device == "cuda" and torch.cuda.is_available():
            print(f"ğŸš€ GPU ì‚¬ìš©: {torch.cuda.get_device_name()}")
        
        return device
    
    def _load_model(self, checkpoint_path: str) -> ThreeTaskDSPNet:
        """
        Load model from checkpoint.
        
        Args:
            checkpoint_path: Path to model checkpoint
            
        Returns:
            Loaded model
        """
        print(f"ğŸ“‚ ëª¨ë¸ ë¡œë”©: {checkpoint_path}")
        
        # Check if checkpoint exists
        if not os.path.exists(checkpoint_path):
            raise FileNotFoundError(f"Checkpoint not found: {checkpoint_path}")
        
        # Load checkpoint
        checkpoint = torch.load(checkpoint_path, map_location=self.device)
        
        # Create model with same config as training
        if 'config' in checkpoint:
            config = checkpoint['config']
            model = ThreeTaskDSPNet(
                num_detection_classes=config.get('num_detection_classes', 29),
                num_surface_classes=config.get('num_surface_classes', 7),
                input_size=config.get('input_size', (512, 512)),
                pretrained_backbone=config.get('pretrained_backbone', True)
            )
        else:
            # Default config
            model = ThreeTaskDSPNet()
        
        # Load state dict
        model.load_state_dict(checkpoint['model_state_dict'])
        model = model.to(self.device)
        model.eval()
        
        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        return model
    
    def test_single_image(self, image_path: str, save_path: str = None) -> dict:
        """
        Test model on a single image.
        
        Args:
            image_path: Path to input image
            save_path: Path to save visualization
            
        Returns:
            Dictionary with predictions and metadata
        """
        # ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
        image = self._preprocess_image(image_path)
        
        # ì¶”ë¡ 
        with torch.no_grad():
            outputs = self.model(image.unsqueeze(0))
        
        # ê²°ê³¼ ì²˜ë¦¬
        results = self._process_outputs(outputs, image_path)
        
        # ì‹œê°í™”
        if save_path:
            self._visualize_results(image_path, results, save_path)
        
        return results
    
    def _preprocess_image(self, image_path: str) -> torch.Tensor:
        """Preprocess image for inference."""
        image = Image.open(image_path).convert('RGB')
        image = image.resize((512, 512))
        
        # ImageNet ì •ê·œí™”
        image_array = np.array(image) / 255.0
        mean = np.array([0.485, 0.456, 0.406])
        std = np.array([0.229, 0.224, 0.225])
        image_array = (image_array - mean) / std
        
        # Tensorë¡œ ë³€í™˜
        image_tensor = torch.from_numpy(image_array.transpose(2, 0, 1)).float()
        return image_tensor.to(self.device)
    
    def _process_outputs(self, outputs: dict, image_path: str) -> dict:
        """Process model outputs."""
        results = {'image_path': image_path}
        
        # Detection ê²°ê³¼ ì²˜ë¦¬ - ìƒˆë¡œìš´ SSD í‘œì¤€ í˜•íƒœ
        detection_cls = outputs['detection_cls']  # (1, num_anchors, num_classes+1)
        detection_reg = outputs['detection_reg']  # (1, num_anchors, 4)
        
        # Softmax for classification scores (background í¬í•¨)
        detection_scores = F.softmax(detection_cls[0], dim=-1)  # (num_anchors, num_classes+1)
        
        # ë°°ê²½ì´ ì•„ë‹Œ í´ë˜ìŠ¤ì˜ ìµœëŒ€ê°’ ì„ íƒ
        max_scores, predicted_classes = torch.max(detection_scores[:, 1:], dim=-1)  # background ì œì™¸
        predicted_classes += 1  # background ì œì™¸í–ˆìœ¼ë¯€ë¡œ +1
        
        # ì„ê³„ê°’ ì´ìƒì˜ ì˜ˆì¸¡ë§Œ ì„ íƒ
        threshold = 0.5
        valid_indices = max_scores > threshold
        
        if valid_indices.sum() > 0:
            valid_scores = max_scores[valid_indices]
            valid_classes = predicted_classes[valid_indices]
            valid_boxes = detection_reg[0, valid_indices, :4]  # bbox coordinates
            
            results['detections'] = {
                'scores': valid_scores.cpu().numpy(),
                'classes': valid_classes.cpu().numpy(), 
                'boxes': valid_boxes.cpu().numpy(),
                'count': len(valid_scores)
            }
        else:
            results['detections'] = {
                'scores': np.array([]),
                'classes': np.array([]),
                'boxes': np.array([]).reshape(0, 4),
                'count': 0
            }
        
        # Surface ê²°ê³¼ ì²˜ë¦¬
        surface_logits = outputs['surface_segmentation']  # (1, 4, 512, 512)
        surface_pred = torch.argmax(surface_logits[0], dim=0)  # (512, 512)
        
        results['surface_segmentation'] = surface_pred.cpu().numpy()
        
        return results
    
    def _visualize_results(self, image_path: str, results: dict, save_path: str):
        """Visualize and save results."""
        # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ
        original_image = Image.open(image_path).convert('RGB')
        original_image = original_image.resize((512, 512))
        original_array = np.array(original_image)
        
        # Figure ìƒì„±
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle(f'TwoTaskDSPNet Results: {os.path.basename(image_path)}', fontsize=16)
        
        # 1. ì›ë³¸ ì´ë¯¸ì§€
        axes[0, 0].imshow(original_array)
        axes[0, 0].set_title('Original Image')
        axes[0, 0].axis('off')
        
        # 2. Detection ê²°ê³¼
        detection_img = original_array.copy()
        detections = results['detections']
        
        if detections['count'] > 0:
            for i in range(detections['count']):
                score = detections['scores'][i]
                class_id = detections['classes'][i] - 1  # 0-based indexing
                box = detections['boxes'][i]
                
                if 0 <= class_id < len(DETECTION_CLASSES):
                    class_name = DETECTION_CLASSES[class_id]
                    
                    # ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ê°„ë‹¨í•œ ë°©ë²•, ì‹¤ì œë¡œëŠ” ì¢Œí‘œ ë³€í™˜ í•„ìš”)
                    x1, y1, x2, y2 = box
                    x1, y1, x2, y2 = int(x1*512), int(y1*512), int(x2*512), int(y2*512)
                    
                    cv2.rectangle(detection_img, (x1, y1), (x2, y2), (0, 255, 0), 2)
                    
                    # ë¼ë²¨ í…ìŠ¤íŠ¸
                    label = f'{class_name}: {score:.2f}'
                    cv2.putText(detection_img, label, (x1, y1-10), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
        
        axes[0, 1].imshow(detection_img)
        axes[0, 1].set_title(f'Object Detection ({detections["count"]} objects)')
        axes[0, 1].axis('off')
        
        # 3. Surface Segmentation ê²°ê³¼
        surface_mask = results['surface_segmentation']
        surface_colored = np.zeros((512, 512, 3), dtype=np.uint8)
        
        for class_id, color in self.surface_colors.items():
            mask = surface_mask == class_id
            surface_colored[mask] = color
        
        axes[1, 0].imshow(surface_colored)
        axes[1, 0].set_title('Surface Segmentation')
        axes[1, 0].axis('off')
        
        # 4. ì˜¤ë²„ë ˆì´ ê²°ê³¼
        overlay = original_array.copy().astype(np.float32)
        surface_colored_norm = surface_colored.astype(np.float32) / 255.0
        
        # ë°°ê²½ì´ ì•„ë‹Œ ë¶€ë¶„ë§Œ ì˜¤ë²„ë ˆì´
        non_background = surface_mask > 0
        overlay[non_background] = 0.6 * overlay[non_background] + 0.4 * (surface_colored_norm[non_background] * 255)
        overlay = overlay.astype(np.uint8)
        
        axes[1, 1].imshow(overlay)
        axes[1, 1].set_title('Original + Surface Overlay')
        axes[1, 1].axis('off')
        
        # ì €ì¥
        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"ğŸ’¾ ì‹œê°í™” ê²°ê³¼ ì €ì¥: {save_path}")
    
    def test_dataset(self, data_loader, num_samples: int = 10, save_dir: str = "test_results"):
        """Test model on dataset samples."""
        os.makedirs(save_dir, exist_ok=True)
        
        self.model.eval()
        
        print(f"\nğŸ§ª ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ ì‹œì‘ ({num_samples}ê°œ ìƒ˜í”Œ)")
        
        sample_count = 0
        for batch_idx, batch in enumerate(tqdm(data_loader, desc="Testing")):
            if sample_count >= num_samples:
                break
            
            images = batch['images'].to(self.device)
            batch_size = images.size(0)
            
            with torch.no_grad():
                outputs = self.model(images)
            
            # ê° ì´ë¯¸ì§€ì— ëŒ€í•´ ì²˜ë¦¬
            for i in range(batch_size):
                if sample_count >= num_samples:
                    break
                
                # ë‹¨ì¼ ì´ë¯¸ì§€ ê²°ê³¼ ì¶”ì¶œ
                single_outputs = {
                    'detection_cls': outputs['detection_cls'][i:i+1],
                    'detection_reg': outputs['detection_reg'][i:i+1],
                    'surface_segmentation': outputs['surface_segmentation'][i:i+1]
                }
                
                # ì›ë³¸ ì´ë¯¸ì§€ ë³µì› (ì—­ì •ê·œí™”)
                image_tensor = images[i].cpu()
                mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)
                std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)
                image_denorm = image_tensor * std + mean
                image_denorm = torch.clamp(image_denorm, 0, 1)
                
                # PIL Imageë¡œ ë³€í™˜
                image_array = (image_denorm.permute(1, 2, 0).numpy() * 255).astype(np.uint8)
                temp_image_path = f"temp_test_image_{sample_count}.jpg"
                Image.fromarray(image_array).save(temp_image_path)
                
                # ê²°ê³¼ ì²˜ë¦¬ ë° ì‹œê°í™”
                results = self._process_outputs(single_outputs, temp_image_path)
                save_path = os.path.join(save_dir, f"test_result_{sample_count:03d}.jpg")
                self._visualize_results(temp_image_path, results, save_path)
                
                # ì„ì‹œ íŒŒì¼ ì œê±°
                os.remove(temp_image_path)
                
                sample_count += 1
        
        print(f"âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ! ê²°ê³¼ëŠ” {save_dir}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


def main():
    """Main function."""
    parser = argparse.ArgumentParser(description='TwoTaskDSPNet Model Testing')
    parser.add_argument('--checkpoint', '-c', type=str, required=True,
                       help='Path to model checkpoint')
    parser.add_argument('--image', '-i', type=str,
                       help='Path to single image for testing')
    parser.add_argument('--dataset', '-d', action='store_true',
                       help='Test on dataset samples')
    parser.add_argument('--num_samples', '-n', type=int, default=10,
                       help='Number of samples to test from dataset')
    parser.add_argument('--save_dir', '-s', type=str, default='test_results',
                       help='Directory to save test results')
    parser.add_argument('--device', type=str, default='auto',
                       help='Device to use (auto, cuda, cpu)')
    
    args = parser.parse_args()
    
    print("ğŸ§ª TwoTaskDSPNet ëª¨ë¸ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # ëª¨ë¸ í…ŒìŠ¤í„° ìƒì„±
    tester = ModelTester(args.checkpoint, args.device)
    
    if args.image:
        # ë‹¨ì¼ ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸
        print(f"\nğŸ–¼ï¸  ë‹¨ì¼ ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸: {args.image}")
        save_path = os.path.join(args.save_dir, f"single_test_{os.path.basename(args.image)}.jpg")
        os.makedirs(args.save_dir, exist_ok=True)
        
        results = tester.test_single_image(args.image, save_path)
        
        print(f"\nğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
        print(f"   Detection: {results['detections']['count']}ê°œ ê°ì²´ ê°ì§€")
        print(f"   Surface: 4ê°œ í´ë˜ìŠ¤ ë¶„í•  ì™„ë£Œ")
        
    elif args.dataset:
        # ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸
        print(f"\nğŸ“š ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ ({args.num_samples}ê°œ ìƒ˜í”Œ)")
        
        # ë°ì´í„° ë¡œë” ìƒì„±
        _, val_loader = create_dataset(
            batch_size=4,
            num_workers=2,
            max_samples=args.num_samples * 2,
            base_dir="data/original_dataset"
        )
        
        tester.test_dataset(val_loader, args.num_samples, args.save_dir)
    
    else:
        print("âŒ --image ë˜ëŠ” --dataset ì˜µì…˜ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
        parser.print_help()


if __name__ == "__main__":
    main() 