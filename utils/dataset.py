"""
Dataset Utilities for TwoTaskDSPNet

Detection + Surface 2íƒœìŠ¤í¬ë¥¼ ìœ„í•œ ë°ì´í„°ì…‹ ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹°.
ê¸°ì¡´ 3íƒœìŠ¤í¬ ì½”ë“œë¥¼ ë‹¨ìˆœí™”í•˜ì—¬ í•„ìˆ˜ ê¸°ëŠ¥ë§Œ ì œê³µí•©ë‹ˆë‹¤.

ì¶”ê°€: Stereo depth ê³„ì‚° ì§€ì›
"""

import os
import torch
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
import numpy as np
import cv2
from PIL import Image
import xml.etree.ElementTree as ET
from collections import defaultdict
import random
from tqdm import tqdm
from typing import Dict, List, Tuple, Optional

# Stereo depth calculation
try:
    from utils.stereo_depth import StereoDepthCalculator
except ImportError:
    try:
        from .stereo_depth import StereoDepthCalculator
    except ImportError:
        print("âš ï¸  StereoDepthCalculator import ì‹¤íŒ¨, ê¸°ë³¸ depth ê³„ì‚° ì‚¬ìš©")
        StereoDepthCalculator = None

# Surface í´ë˜ìŠ¤ ì •ì˜ (XMLì—ì„œ ì¶”ì¶œí•œ ë¼ë²¨ ê¸°ë°˜)
SURFACE_LABELS = [
    'background',         # 0
    'alley',             # 1
    'bike_lane',         # 2
    'braille_guide_blocks',  # 3
    'caution_zone',      # 4
    'roadway',           # 5
    'sidewalk'           # 6
]

SURFACE_LABEL_TO_ID = {label: idx for idx, label in enumerate(SURFACE_LABELS)}

# Detection í´ë˜ìŠ¤ (29ê°œ - ì‹¤ì œ XMLì—ì„œ í™•ì¸ëœ ëª¨ë“  ë¼ë²¨)
DETECTION_CLASSES = [
    'barricade', 'bench', 'bicycle', 'bollard', 'bus', 'car', 'carrier', 'cat',
    'chair', 'dog', 'fire_hydrant', 'kiosk', 'motorcycle', 'movable_signage', 
    'parking_meter', 'person', 'pole', 'potted_plant', 'power_controller', 
    'scooter', 'stop', 'stroller', 'table', 'traffic_light', 'traffic_light_controller',
    'traffic_sign', 'tree_trunk', 'truck', 'wheelchair'
]

# Depth í´ë˜ìŠ¤ ì •ì˜ (ë‹¨ìˆœí•œ ê±°ë¦¬ íšŒê·€)
DEPTH_RANGE = (0.0, 255.0)  # ë¯¸í„° ë‹¨ìœ„

class ThreeTaskDataset(Dataset):
    """
    Dataset for Detection + Surface + Depth three-task learning.
    
    ê° íƒœìŠ¤í¬ëŠ” ì™„ì „íˆ ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬:
    - Detection: bbox ì˜ˆì¸¡ (ê°ì²´ë³„ 5ì°¨ì›)
    - Surface: pixel-wise segmentation (7í´ë˜ìŠ¤)  
    - Depth: pixel-wise regression (ì—°ì†ê°’)
    """
    
    def __init__(self,
                 base_dir: str = "data/original_dataset",
                 mode: str = "train",
                 train_ratio: float = 0.8,
                 max_samples: int = 2000,
                 input_size: Tuple[int, int] = (512, 512)):
        """
        Initialize three-task dataset.
        
        Args:
            base_dir: Path to original dataset
            mode: 'train' or 'val'
            train_ratio: Train/validation split ratio
            max_samples: Maximum number of samples to load
            input_size: Input image size (H, W)
        """
        self.base_dir = base_dir
        self.mode = mode
        self.input_size = input_size
        
        # Data transforms
        self.transform = transforms.Compose([
            transforms.Resize(input_size),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        # Load and split data
        print("ğŸ” 3ê°œ íƒœìŠ¤í¬ ë°ì´í„° ë¡œë”© ì¤‘...")
        self.detection_data = self._load_detection_data()[:max_samples//3]
        self.surface_data = self._load_surface_data()[:max_samples//3] 
        self.depth_data = self._load_depth_data()[:max_samples//3]
        
        self._split_data(train_ratio)
        self._create_sample_list()
        
        print(f"âœ… ThreeTaskDataset ({mode}) ìƒì„±:")
        print(f"   Detection: {len(self.final_detection)}ê°œ (bbox ì˜ˆì¸¡)")
        print(f"   Surface: {len(self.final_surface)}ê°œ (pixel segmentation)")
        print(f"   Depth: {len(self.final_depth)}ê°œ (pixel regression)")
        print(f"   ì „ì²´: {len(self.samples)}ê°œ")
    
    def _load_detection_data(self) -> List[Dict]:
        """Load detection data."""
        detection_dir = os.path.join(self.base_dir, "bbox")
        data = []
        
        if not os.path.exists(detection_dir):
            print(f"âš ï¸  Detection ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {detection_dir}")
            return data
        
        subfolders = [d for d in os.listdir(detection_dir) 
                     if os.path.isdir(os.path.join(detection_dir, d))]
        print(f"ğŸ” Detection í´ë” ë°œê²¬: {len(subfolders)}ê°œ")
        
        for subfolder in subfolders:  # ëª¨ë“  í´ë” ì‚¬ìš©
            subfolder_path = os.path.join(detection_dir, subfolder)
            xml_files = [f for f in os.listdir(subfolder_path) if f.endswith('.xml')]
            print(f"   ğŸ“ {subfolder}: XML={len(xml_files)}ê°œ")
            
            if xml_files:
                xml_path = os.path.join(subfolder_path, xml_files[0])
                try:
                    tree = ET.parse(xml_path)
                    root = tree.getroot()
                    
                    image_count = 0
                    for image_elem in root.findall('image'):  # ëª¨ë“  ì´ë¯¸ì§€ ì‚¬ìš©
                        image_name = image_elem.get('name')
                        if image_name:
                            image_path = os.path.join(subfolder_path, image_name)
                            if os.path.exists(image_path):
                                boxes = []
                                for box in image_elem.findall('box'):
                                    label = box.get('label')
                                    if label in DETECTION_CLASSES:
                                        try:
                                            xtl = float(box.get('xtl'))
                                            ytl = float(box.get('ytl'))
                                            xbr = float(box.get('xbr'))
                                            ybr = float(box.get('ybr'))
                                            class_id = DETECTION_CLASSES.index(label)
                                            boxes.append([xtl, ytl, xbr, ybr, class_id])
                                        except:
                                            continue
                                
                                if boxes:
                                    data.append({
                                        'image_path': image_path,
                                        'boxes': boxes,
                                        'task': 'detection'
                                    })
                                    image_count += 1
                    print(f"      â†’ {image_count}ê°œ ì´ë¯¸ì§€ ë¡œë“œë¨")
                except Exception as e:
                    print(f"âš ï¸  {subfolder} XML íŒŒì‹± ì˜¤ë¥˜: {e}")
                    continue
        
        print(f"âœ… ì´ Detection ë°ì´í„°: {len(data)}ê°œ")
        return data
    
    def _load_surface_data(self) -> List[Dict]:
        """Load surface data with proper XML structure understanding."""
        surface_dir = os.path.join(self.base_dir, "surface")
        data = []
        
        if not os.path.exists(surface_dir):
            print(f"âš ï¸  Surface ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {surface_dir}")
            return data
        
        subfolders = [d for d in os.listdir(surface_dir) 
                     if os.path.isdir(os.path.join(surface_dir, d))]
        print(f"ğŸ” Surface í´ë” ë°œê²¬: {len(subfolders)}ê°œ")
        
        for subfolder in subfolders:  # ëª¨ë“  í´ë” ì‚¬ìš©
            subfolder_path = os.path.join(surface_dir, subfolder)
            mask_dir = os.path.join(subfolder_path, 'MASK')
            
            # XML íŒŒì¼ ì°¾ê¸° (í´ë”ë‹¹ í•˜ë‚˜)
            xml_files = [f for f in os.listdir(subfolder_path) if f.endswith('.xml')]
            print(f"   ğŸ“ {subfolder}: XML={len(xml_files)}ê°œ, MASK í´ë”={'ì¡´ì¬' if os.path.exists(mask_dir) else 'ì—†ìŒ'}")
            
            if not xml_files or not os.path.exists(mask_dir):
                continue
                
            xml_path = os.path.join(subfolder_path, xml_files[0])
            
            try:
                tree = ET.parse(xml_path)
                root = tree.getroot()
                
                image_count = 0
                # ê° ì´ë¯¸ì§€ë³„ë¡œ ì²˜ë¦¬ (XML êµ¬ì¡° ì˜¬ë°”ë¥´ê²Œ ì´í•´)
                for image_elem in root.findall('image'):
                    image_name = image_elem.get('name')
                    if not image_name:
                        continue
                    
                    # ì´ë¯¸ì§€ íŒŒì¼ê³¼ ë§ˆìŠ¤í¬ íŒŒì¼ ê²½ë¡œ
                    image_path = os.path.join(subfolder_path, image_name)
                    mask_name = os.path.splitext(image_name)[0] + '.png'
                    mask_path = os.path.join(mask_dir, mask_name)
                    
                    if os.path.exists(image_path) and os.path.exists(mask_path):
                        # ì´ ì´ë¯¸ì§€ì—ì„œ ì‹¤ì œ ì‚¬ìš©ëœ ë¼ë²¨ë“¤ ì¶”ì¶œ
                        used_labels = set()
                        label_attributes = {}
                        
                        for polygon in image_elem.findall('polygon'):
                            label = polygon.get('label')
                            if label:
                                used_labels.add(label)
                                
                                # ì†ì„±ë„ ì¶”ì¶œ
                                attr_elem = polygon.find('attribute[@name="attribute"]')
                                if attr_elem is not None and attr_elem.text:
                                    label_attributes[label] = attr_elem.text
                        
                        data.append({
                            'image_path': image_path,
                            'mask_path': mask_path,
                            'task': 'surface',
                            'used_labels': list(used_labels),  # ì‹¤ì œ ì‚¬ìš©ëœ ë¼ë²¨ë“¤
                            'label_attributes': label_attributes  # ë¼ë²¨ë³„ ì†ì„±
                        })
                        image_count += 1
                        
                print(f"      â†’ {image_count}ê°œ ì´ë¯¸ì§€ ë¡œë“œë¨")
                        
            except Exception as e:
                print(f"âš ï¸  {subfolder} XML íŒŒì‹± ì˜¤ë¥˜: {e}")
                continue
        
        print(f"âœ… ì´ Surface ë°ì´í„°: {len(data)}ê°œ")
        return data
    
    def _load_depth_data(self) -> List[Dict]:
        """Load depth data with proper stereo depth structure."""
        depth_dir = os.path.join(self.base_dir, "depth")
        data = []
        
        if not os.path.exists(depth_dir):
            print(f"âš ï¸  Depth ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {depth_dir}")
            return data
        
        subfolders = [d for d in os.listdir(depth_dir) 
                     if os.path.isdir(os.path.join(depth_dir, d))]
        print(f"ğŸ” Depth í´ë” ë°œê²¬: {len(subfolders)}ê°œ")
        
        for subfolder in subfolders:  # ëª¨ë“  í´ë” ì‚¬ìš©
            subfolder_path = os.path.join(depth_dir, subfolder)
            
            # ê° í´ë”ì—ì„œ ì‹¤ì œ íŒŒì¼ íŒ¨í„´ì— ë§ëŠ” íŒŒì¼ë“¤ ì°¾ê¸°
            files = os.listdir(subfolder_path)
            
            # ì‹¤ì œ íŒŒì¼ íŒ¨í„´: ZED1_KSC_XXXXXX_left.png, ZED1_KSC_XXXXXX_disp16.png, ZED1_KSC_XXXXXX_confidence.png
            left_images = [f for f in files if f.endswith('_left.png')]  # Raw_Left â†’ _left.png
            disp16_files = [f for f in files if f.endswith('_disp16.png')]  # Disparity16
            confidence_files = [f for f in files if f.endswith('_confidence.png') and '_confidence_save.png' not in f]  # Confidence (save ì œì™¸)
            
            print(f"   ğŸ“ {subfolder}: Left={len(left_images)}ê°œ, Disp16={len(disp16_files)}ê°œ, Conf={len(confidence_files)}ê°œ")
            
            # ê° ì´ë¯¸ì§€ì— ëŒ€í•´ ë§¤ì¹­
            image_count = 0
            for left_img in left_images:
                # íŒŒì¼ëª…ì—ì„œ ë² ì´ìŠ¤ ì´ë¦„ ì¶”ì¶œ (ì˜ˆ: ZED1_KSC_001251_left.png â†’ ZED1_KSC_001251)
                base_name = left_img.replace('_left.png', '')
                
                # ë§¤ì¹­ë˜ëŠ” disparityì™€ confidence íŒŒì¼ ì°¾ê¸°
                disp16_file = f"{base_name}_disp16.png"
                confidence_file = f"{base_name}_confidence.png"
                
                left_path = os.path.join(subfolder_path, left_img)
                disp16_path = os.path.join(subfolder_path, disp16_file)
                confidence_path = os.path.join(subfolder_path, confidence_file)
                
                # ëª¨ë“  íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                if (os.path.exists(left_path) and 
                    os.path.exists(disp16_path) and 
                    os.path.exists(confidence_path)):
                    
                    data.append({
                        'image_path': left_path,        # Left ì´ë¯¸ì§€ (ì…ë ¥)
                        'disparity_path': disp16_path,  # Disparity16 (depth ì •ë³´)
                        'confidence_path': confidence_path,  # Confidence (ì‹ ë¢°ë„)
                        'base_name': base_name,         # ë² ì´ìŠ¤ íŒŒì¼ëª…
                        'task': 'depth'
                    })
                    image_count += 1
                else:
                    # ë””ë²„ê¹…: ëˆ„ë½ëœ íŒŒì¼ í™•ì¸
                    missing = []
                    if not os.path.exists(left_path): missing.append('left')
                    if not os.path.exists(disp16_path): missing.append('disp16')
                    if not os.path.exists(confidence_path): missing.append('confidence')
                    if missing:
                        print(f"      âš ï¸  {base_name}: ëˆ„ë½ íŒŒì¼ = {missing}")
                    
            print(f"      â†’ {image_count}ê°œ depth ìƒ˜í”Œ ë¡œë“œë¨")
        
        print(f"âœ… ì´ Depth ë°ì´í„°: {len(data)}ê°œ")
        return data
    
    def _split_data(self, train_ratio: float):
        """Split data into train/validation."""
        # Detection split
        random.shuffle(self.detection_data)
        split_idx = int(len(self.detection_data) * train_ratio)
        
        if self.mode == 'train':
            self.final_detection = self.detection_data[:split_idx]
        else:
            self.final_detection = self.detection_data[split_idx:]
        
        # Surface split
        random.shuffle(self.surface_data)
        split_idx = int(len(self.surface_data) * train_ratio)
        
        if self.mode == 'train':
            self.final_surface = self.surface_data[:split_idx]
        else:
            self.final_surface = self.surface_data[split_idx:]
        
        # Depth split
        random.shuffle(self.depth_data)
        split_idx = int(len(self.depth_data) * train_ratio)
        
        if self.mode == 'train':
            self.final_depth = self.depth_data[:split_idx]
        else:
            self.final_depth = self.depth_data[split_idx:]
    
    def _create_sample_list(self):
        """Create unified sample list."""
        self.samples = []
        
        # Add detection samples
        for item in self.final_detection:
            self.samples.append(('detection', item))
        
        # Add surface samples
        for item in self.final_surface:
            self.samples.append(('surface', item))
        
        # Add depth samples
        for item in self.final_depth:
            self.samples.append(('depth', item))
    
    def __len__(self) -> int:
        return len(self.samples)
    
    def __getitem__(self, idx: int) -> Dict:
        task_type, item = self.samples[idx]
        
        if task_type == 'detection':
            return self._get_detection_sample(item)
        elif task_type == 'surface':
            return self._get_surface_sample(item)
        elif task_type == 'depth':
            return self._get_depth_sample(item)
    
    def _get_detection_sample(self, item: Dict) -> Dict:
        """Get detection sample without depth processing."""
        try:
            image = Image.open(item['image_path']).convert('RGB')
            image_tensor = self.transform(image)
            
            # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°
            original_width, original_height = image.size
            
            # ê°„ë‹¨í•œ bbox ì²˜ë¦¬ (depthëŠ” ì œê±°)
            for bbox_data in item['boxes']:
                # 5ì°¨ì› ìœ ì§€: [x1, y1, x2, y2, class_id]
                # depth ê´€ë ¨ distanceëŠ” ì œê±°
                pass
            
            return {
                'image': image_tensor,
                'task': 'detection',
                'boxes': torch.tensor(item['boxes'], dtype=torch.float32),  # 5ì°¨ì›: [x1,y1,x2,y2,cls]
                'has_detection': True,
                'has_surface': False
            }
        except Exception as e:
            print(f"âš ï¸  Detection ìƒ˜í”Œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            # Return dummy sample on error
            return {
                'image': torch.zeros(3, *self.input_size),
                'task': 'detection',
                'boxes': torch.zeros(1, 5),  # 5ì°¨ì›ìœ¼ë¡œ ë³€ê²½
                'has_detection': True,
                'has_surface': False
            }
    
    def _get_surface_sample(self, item: Dict) -> Dict:
        """Get surface sample using XML polygon data."""
        try:
            # ì´ë¯¸ì§€ ë¡œë“œ
            image = Image.open(item['image_path']).convert('RGB')
            original_width, original_height = image.size
            
            # XMLì—ì„œ í´ë¦¬ê³¤ ì •ë³´ ì¶”ì¶œ
            surface_mask = np.zeros((original_height, original_width), dtype=np.uint8)
            
            # XML íŒŒì¼ ê²½ë¡œ ì¶”ì¶œ
            xml_path = None
            for file in os.listdir(os.path.dirname(item['image_path'])):
                if file.endswith('.xml'):
                    xml_path = os.path.join(os.path.dirname(item['image_path']), file)
                    break
            
            if xml_path and os.path.exists(xml_path):
                try:
                    tree = ET.parse(xml_path)
                    root = tree.getroot()
                    
                    # í˜„ì¬ ì´ë¯¸ì§€ì˜ í´ë¦¬ê³¤ë“¤ ì°¾ê¸°
                    image_name = os.path.basename(item['image_path'])
                    for image_elem in root.findall('image'):
                        if image_elem.get('name') == image_name:
                            # ì´ ì´ë¯¸ì§€ì˜ ëª¨ë“  í´ë¦¬ê³¤ ì²˜ë¦¬
                            for polygon in image_elem.findall('polygon'):
                                label = polygon.get('label')
                                points_str = polygon.get('points')
                                
                                if label in SURFACE_LABEL_TO_ID and points_str:
                                    class_id = SURFACE_LABEL_TO_ID[label]
                                    
                                    # í¬ì¸íŠ¸ íŒŒì‹± (x1,y1;x2,y2;... í˜•íƒœ)
                                    try:
                                        points = []
                                        for point_pair in points_str.split(';'):
                                            if ',' in point_pair:
                                                x, y = point_pair.split(',')
                                                points.append([int(float(x)), int(float(y))])
                                        
                                        if len(points) >= 3:  # ìµœì†Œ 3ê°œ ì ì´ ìˆì–´ì•¼ í´ë¦¬ê³¤
                                            # í´ë¦¬ê³¤ì„ ë§ˆìŠ¤í¬ì— ê·¸ë¦¬ê¸°
                                            cv2.fillPoly(surface_mask, [np.array(points)], class_id)
                                    except:
                                        continue
                            break
                except Exception as e:
                    print(f"âš ï¸  XML íŒŒì‹± ì˜¤ë¥˜: {e}")
            
            # ë§ˆìŠ¤í¬ ë¦¬ì‚¬ì´ì¦ˆ
            surface_mask = cv2.resize(surface_mask, self.input_size, interpolation=cv2.INTER_NEAREST)
            
            # ì´ë¯¸ì§€ ë³€í™˜
            image_tensor = self.transform(image)
            
            return {
                'image': image_tensor,
                'task': 'surface',
                'surface_mask': torch.tensor(surface_mask, dtype=torch.long),
                'has_detection': False,
                'has_surface': True
            }
            
        except Exception as e:
            print(f"âš ï¸  Surface ìƒ˜í”Œ ë¡œë”© ì˜¤ë¥˜: {e}")
            # Return dummy sample on error
            return {
                'image': torch.zeros(3, *self.input_size),
                'task': 'surface',
                'surface_mask': torch.zeros(*self.input_size, dtype=torch.long),
                'has_detection': False,
                'has_surface': True
            }
    
    def _get_depth_sample(self, item: Dict) -> Dict:
        """Get depth sample with proper SafeStrp stereo depth processing."""
        try:
            # Left ì´ë¯¸ì§€ ë¡œë“œ (ì…ë ¥ ì´ë¯¸ì§€)
            image = Image.open(item['image_path']).convert('RGB')
            image_tensor = self.transform(image)
            
            # Disparity16ì™€ Confidence ë¡œë“œ (16-bit ìœ ì§€)
            disparity16 = cv2.imread(item['disparity_path'], cv2.IMREAD_UNCHANGED)
            confidence = cv2.imread(item['confidence_path'], cv2.IMREAD_GRAYSCALE)
            
            if disparity16 is None:
                raise ValueError(f"Disparity16 ë¡œë“œ ì‹¤íŒ¨: {item['disparity_path']}")
            if confidence is None:
                raise ValueError(f"Confidence ë¡œë“œ ì‹¤íŒ¨: {item['confidence_path']}")
            
            # StereoDepthCalculator ì‚¬ìš©í•˜ì—¬ ì •í™•í•œ depth ê³„ì‚°
            folder_path = os.path.dirname(item['disparity_path'])
            config_files = [f for f in os.listdir(folder_path) if f.endswith('.conf')]
            
            if StereoDepthCalculator is not None:
                # Config íŒŒì¼ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
                if config_files:
                    config_path = os.path.join(folder_path, config_files[0])
                    try:
                        calculator = StereoDepthCalculator.from_config_file(config_path, camera_type="2K")
                    except Exception as e:
                        print(f"   âš ï¸  Config ë¡œë“œ ì‹¤íŒ¨ ({item['base_name']}): {e}")
                        calculator = StereoDepthCalculator()
                else:
                    calculator = StereoDepthCalculator()
                
                # Disparity16ë¥¼ ì‹¤ì œ depth(mm)ë¡œ ë³€í™˜
                depth_mm, valid_mask = calculator.disparity_to_depth(disparity16, confidence)
                
                # í•™ìŠµìš©ìœ¼ë¡œ 0-255 ë²”ìœ„ë¡œ ì •ê·œí™”
                if valid_mask.any():
                    depth_normalized = calculator.normalize_depth_for_learning(
                        depth_mm, valid_mask, target_range=(0.0, 255.0)
                    )
                else:
                    print(f"   âš ï¸  ìœ íš¨í•œ depth í”½ì…€ì´ ì—†ìŒ ({item['base_name']})")
                    depth_normalized = np.zeros_like(depth_mm)
                    
            else:
                # Fallback: ê°„ë‹¨í•œ depth ê³„ì‚° (StereoDepthCalculator import ì‹¤íŒ¨ ì‹œ)
                print(f"   âš ï¸  StereoDepthCalculator ì—†ìŒ, fallback ì‚¬ìš© ({item['base_name']})")
                focal_length = 1400.15
                baseline = 119.975
                
                disparity_float = disparity16.astype(np.float32)
                valid_mask = (disparity_float > 1.0) & (confidence > 0)
                
                depth_mm = np.zeros_like(disparity_float)
                if valid_mask.any():
                    depth_mm[valid_mask] = (baseline * focal_length) / disparity_float[valid_mask]
                    depth_mm = np.clip(depth_mm, 200, 200000)  # 0.2m ~ 200m
                
                # ê°„ë‹¨í•œ ì •ê·œí™”
                if valid_mask.any():
                    valid_depths = depth_mm[valid_mask]
                    min_d, max_d = valid_depths.min(), valid_depths.max()
                    depth_normalized = np.zeros_like(depth_mm)
                    if max_d > min_d:
                        depth_normalized[valid_mask] = ((valid_depths - min_d) / (max_d - min_d)) * 255.0
                    else:
                        depth_normalized[valid_mask] = 127.5
                else:
                    depth_normalized = np.zeros_like(depth_mm)
            
            # Resize to target input size
            depth_resized = cv2.resize(depth_normalized, self.input_size, interpolation=cv2.INTER_NEAREST)
            confidence_resized = cv2.resize(confidence / 255.0, self.input_size, interpolation=cv2.INTER_NEAREST)
            
            return {
                'image': image_tensor,
                'depth_map': torch.tensor(depth_resized, dtype=torch.float32),
                'confidence_mask': torch.tensor(confidence_resized, dtype=torch.float32),
                'task': 'depth',
                'has_detection': False,
                'has_surface': False,
                'base_name': item['base_name']
            }
            
        except Exception as e:
            print(f"âš ï¸  Depth ìƒ˜í”Œ ì²˜ë¦¬ ì˜¤ë¥˜ ({item.get('base_name', 'unknown')}): {e}")
            return {
                'image': torch.zeros(3, *self.input_size),
                'depth_map': torch.zeros(self.input_size, dtype=torch.float32),
                'confidence_mask': torch.zeros(self.input_size, dtype=torch.float32),
                'task': 'depth',
                'has_detection': False,
                'has_surface': False,
                'base_name': item.get('base_name', 'error')
            }


def collate_fn(batch: List[Dict]) -> Dict:
    """Custom collate function for Detection + Surface + Depth tasks."""
    images = torch.stack([item['image'] for item in batch])
    tasks = [item['task'] for item in batch]
    has_detection = [item.get('has_detection', False) for item in batch]
    has_surface = [item.get('has_surface', False) for item in batch]
    has_depth = [item.get('task') == 'depth' for item in batch]
    
    # Collect surface masks
    surface_masks = []
    for item in batch:
        if 'surface_mask' in item:
            surface_masks.append(item['surface_mask'])
        else:
            surface_masks.append(torch.zeros(512, 512, dtype=torch.long))
    
    # Collect detection data and separate bbox from labels (SSD êµ¬ì¡°ì— ë§ê²Œ)
    detection_boxes = []  # bbox ì¢Œí‘œë§Œ (N, 4)
    detection_labels = []  # í´ë˜ìŠ¤ ë¼ë²¨ë§Œ (N,)
    
    for item in batch:
        if 'boxes' in item and item['boxes'].size(0) > 0:
            boxes_data = item['boxes']  # (N, 5) - [x1, y1, x2, y2, class]
            
            # bbox ì¢Œí‘œ (4ì°¨ì›)ì™€ í´ë˜ìŠ¤ ë¼ë²¨ ë¶„ë¦¬
            bbox_coords = boxes_data[:, :4]  # (N, 4) - [x1, y1, x2, y2]
            labels = boxes_data[:, 4].long()  # (N,) - class_id
            
            detection_boxes.append(bbox_coords)
            detection_labels.append(labels)
        else:
            # ë¹ˆ ë°•ìŠ¤ ì²˜ë¦¬
            detection_boxes.append(torch.zeros(1, 4, dtype=torch.float32))
            detection_labels.append(torch.zeros(1, dtype=torch.long))
    
    # Collect depth data
    depth_maps = []
    confidence_masks = []
    for item in batch:
        if 'depth_map' in item:
            depth_maps.append(item['depth_map'])
            confidence_masks.append(item['confidence_mask'])
        else:
            depth_maps.append(torch.zeros(512, 512, dtype=torch.float32))
            confidence_masks.append(torch.zeros(512, 512, dtype=torch.float32))
    
    return {
        'images': images,
        'tasks': tasks,
        'has_detection': has_detection,
        'has_surface': has_surface,
        'has_depth': has_depth,
        'surface_masks': torch.stack(surface_masks),
        'detection_boxes': detection_boxes,    # List[Tensor(N, 4)] - bbox ì¢Œí‘œë§Œ
        'detection_labels': detection_labels,  # List[Tensor(N,)] - í´ë˜ìŠ¤ ë¼ë²¨ë§Œ  
        'depth_maps': torch.stack(depth_maps),
        'confidence_masks': torch.stack(confidence_masks),
    }


def create_dataset(base_dir: str = "data/original_dataset", 
                  batch_size: int = 8, 
                  num_workers: int = 4, 
                  max_samples: int = 2000) -> Tuple[DataLoader, DataLoader]:
    """
    Create train and validation dataloaders.
    
    Args:
        base_dir: Path to dataset
        batch_size: Batch size
        num_workers: Number of workers
        max_samples: Maximum samples to load
        
    Returns:
        Tuple of (train_loader, val_loader)
    """
    print(f"ğŸ”§ ë°ì´í„°ì…‹ ìƒì„± ì¤‘...")
    
    train_dataset = ThreeTaskDataset(
        base_dir=base_dir,
        mode='train', 
        max_samples=max_samples
    )
    val_dataset = ThreeTaskDataset(
        base_dir=base_dir,
        mode='val', 
        max_samples=max_samples//4
    )
    
    train_loader = DataLoader(
        train_dataset, 
        batch_size=batch_size, 
        shuffle=True, 
        num_workers=num_workers,
        pin_memory=False,  # ë©”ëª¨ë¦¬ ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ ë¹„í™œì„±í™”
        drop_last=True,
        collate_fn=collate_fn  # ì»¤ìŠ¤í…€ collate í•¨ìˆ˜ ì‚¬ìš©
    )
    val_loader = DataLoader(
        val_dataset, 
        batch_size=batch_size, 
        shuffle=False, 
        num_workers=num_workers,
        pin_memory=False,  # ë©”ëª¨ë¦¬ ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ ë¹„í™œì„±í™”
        drop_last=False,
        collate_fn=collate_fn  # ì»¤ìŠ¤í…€ collate í•¨ìˆ˜ ì‚¬ìš©
    )
    
    return train_loader, val_loader


def create_massive_dataset(base_dir: str = "data/15.ì¸ë„ë³´í–‰ì˜ìƒ", 
                          batch_size: int = 24, 
                          num_workers: int = 0,  # multiprocessing ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ 0ìœ¼ë¡œ ì„¤ì •
                          max_samples: int = 5000000) -> Tuple[DataLoader, DataLoader]:
    """
    Create massive dataset loaders for full-scale training.
    
    Args:
        base_dir: Path to massive dataset (15.ì¸ë„ë³´í–‰ì˜ìƒ)
        batch_size: Large batch size for full training
        num_workers: More workers for data loading
        max_samples: Very large sample count
        
    Returns:
        Tuple of (train_loader, val_loader)
    """
    print(f"ğŸš€ ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ ìƒì„± ì¤‘...")
    
    train_dataset = ThreeTaskDataset(
        base_dir=base_dir,
        mode='train', 
        max_samples=max_samples
    )
    val_dataset = ThreeTaskDataset(
        base_dir=base_dir,
        mode='val', 
        max_samples=max_samples//10  # ê²€ì¦ ë°ì´í„°ëŠ” 10%
    )
    
    # persistent_workersëŠ” num_workers > 0ì¼ ë•Œë§Œ ì‚¬ìš©
    use_persistent_workers = num_workers > 0
    
    train_loader = DataLoader(
        train_dataset, 
        batch_size=batch_size, 
        shuffle=True, 
        num_workers=num_workers,
        pin_memory=True,
        drop_last=True,
        persistent_workers=use_persistent_workers,  # ì¡°ê±´ë¶€ í™œì„±í™”
        collate_fn=collate_fn  # ì»¤ìŠ¤í…€ collate í•¨ìˆ˜ ì‚¬ìš©
    )
    val_loader = DataLoader(
        val_dataset, 
        batch_size=batch_size//2,  # ê²€ì¦ì€ ì ˆë°˜ ë°°ì¹˜ í¬ê¸°
        shuffle=False, 
        num_workers=max(1, num_workers//2) if num_workers > 0 else 0,
        pin_memory=True,
        drop_last=False,
        persistent_workers=use_persistent_workers,
        collate_fn=collate_fn  # ì»¤ìŠ¤í…€ collate í•¨ìˆ˜ ì‚¬ìš©
    )
    
    return train_loader, val_loader


if __name__ == "__main__":
    # Test dataset
    print("ğŸ§ª ThreeTaskDataset í…ŒìŠ¤íŠ¸")
    
    train_loader, val_loader = create_dataset(batch_size=2, max_samples=100)
    
    print(f"Train batches: {len(train_loader)}")
    print(f"Val batches: {len(val_loader)}")
    
    # Test one batch
    for batch in train_loader:
        print(f"Batch shape: {batch['images'].shape}")
        print(f"Tasks: {batch['tasks']}")
        break 