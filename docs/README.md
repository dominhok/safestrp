# SafeStrp - ì¸ë„ë³´í–‰ ì•ˆì „ì„ ìœ„í•œ 3íƒœìŠ¤í¬ ë©€í‹°íƒœìŠ¤í¬ í•™ìŠµ

## ğŸ¯ í”„ë¡œì íŠ¸ ê°œìš”

**SafeStrp**ëŠ” ì¸ë„ë³´í–‰ ì•ˆì „ì„ ìœ„í•œ **Detection + Surface + Depth 3íƒœìŠ¤í¬ ë©€í‹°íƒœìŠ¤í¬ í•™ìŠµ** ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
ì›ë³¸ DSPNet (MXNet) êµ¬ì¡°ë¥¼ **PyTorchë¡œ ì™„ì „íˆ í¬íŒ…**í•˜ê³  í˜„ëŒ€ì ì¸ ë”¥ëŸ¬ë‹ ì•„í‚¤í…ì²˜ë¡œ ê°œì„ í–ˆìŠµë‹ˆë‹¤.

### ğŸš€ **ì£¼ìš” ì„±ê³¼**
- âœ… **ì™„ì „í•œ PyTorch í¬íŒ…**: MXNet â†’ PyTorch ì „ì²´ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ
- âœ… **3íƒœìŠ¤í¬ ì™„ë²½ í†µí•©**: Detection + Surface + Depth í˜¸í™˜ì„± ì™„ì „ í•´ê²°
- âœ… **SSD êµ¬ì¡° ìµœì í™”**: í‘œì¤€ Object Detection ë°©ì‹ìœ¼ë¡œ êµ¬í˜„
- âœ… **IoU ê¸°ë°˜ ì•µì»¤ ë§¤ì¹­**: Positive/Negative/Ignore 3ë‹¨ê³„ ì²˜ë¦¬
- âœ… **ì‹¤ì œ í´ë˜ìŠ¤ í™œìš©**: 1-29 ë²”ìœ„ì˜ ì •í™•í•œ 29ê°œ í´ë˜ìŠ¤ ID ì‚¬ìš©
- âœ… **í˜„ëŒ€ì  ì•„í‚¤í…ì²˜**: íƒ€ì… íŒíŠ¸ + ë¬¸ì„œí™” + ëª¨ë“ˆí™” êµ¬ì¡°

### ğŸ”¥ **í•µì‹¬ ê¸°ìˆ ì  í˜ì‹ **
- **SSD êµ¬ì¡° í‘œì¤€í™”**: Distance regression ì œê±°ë¡œ ìˆœìˆ˜ Object Detection êµ¬í˜„
- **ë°ì´í„° ë¶„ë¦¬ ì²˜ë¦¬**: 5ì°¨ì› ê²°í•© ë°ì´í„°ë¥¼ bbox(4D) + labels(1D)ë¡œ ìë™ ë¶„ë¦¬
- **ì•ˆì •ì  Loss ê³„ì‚°**: `ignore_index=-1` ì²˜ë¦¬ë¡œ ì• ë§¤í•œ ì•µì»¤ ë¬´ì‹œ
- **Hard Negative Mining**: 3:1 ë¹„ìœ¨ì˜ íš¨ìœ¨ì  í•™ìŠµ
- **Depth ìŠ¤ì¼€ì¼ ì¼ê´€ì„±**: 256 ìŠ¤ì¼€ì¼ ê³ ì •ìœ¼ë¡œ ì•ˆì •ì  depth ì²˜ë¦¬

## ğŸ—ï¸ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
safestrp/
â”œâ”€â”€ src/                        # ğŸ¯ í•µì‹¬ ì†ŒìŠ¤ ì½”ë“œ (PyTorch)
â”‚   â”œâ”€â”€ __init__.py            # íŒ¨í‚¤ì§€ ì´ˆê¸°í™” ë° ì£¼ìš” í´ë˜ìŠ¤ export
â”‚   â”œâ”€â”€ model.py               # ThreeTaskDSPNet ë©”ì¸ ëª¨ë¸ (329 lines)
â”‚   â”œâ”€â”€ backbone.py            # ResNet-50 ê¸°ë°˜ DSPNetBackbone (79 lines)
â”‚   â”œâ”€â”€ heads.py              # Detection + Surface + Depth í—¤ë“œ (498 lines)
â”‚   â”œâ”€â”€ losses.py             # í†µí•© ì†ì‹¤í•¨ìˆ˜ ì‹œìŠ¤í…œ (954 lines)
â”‚   â”œâ”€â”€ anchors.py            # SSD ì•µì»¤ ìƒì„±ê¸° (249 lines)
â”‚   â””â”€â”€ nms.py                # NMS ë° í›„ì²˜ë¦¬ (426 lines)
â”œâ”€â”€ scripts/                   # ğŸ”§ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ë“¤
â”‚   â”œâ”€â”€ train.py              # ë©”ì¸ í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸ (563 lines)
â”‚   â””â”€â”€ test.py               # ëª¨ë¸ í…ŒìŠ¤íŠ¸ ë° ì‹œê°í™” (357 lines)
â”œâ”€â”€ configs/                   # âš™ï¸ ì„¤ì • ê´€ë¦¬ ì‹œìŠ¤í…œ
â”‚   â”œâ”€â”€ __init__.py           # ì„¤ì • íŒ¨í‚¤ì§€ ì´ˆê¸°í™”
â”‚   â””â”€â”€ config.py             # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • í´ë˜ìŠ¤ (320 lines)
â”œâ”€â”€ utils/                     # ğŸ› ï¸ ìœ í‹¸ë¦¬í‹°
â”‚   â”œâ”€â”€ __init__.py           # ìœ í‹¸ë¦¬í‹° íŒ¨í‚¤ì§€
â”‚   â”œâ”€â”€ dataset.py            # 3íƒœìŠ¤í¬ ë°ì´í„°ì…‹ ì²˜ë¦¬ (755 lines)
â”‚   â””â”€â”€ stereo_depth.py       # ìŠ¤í…Œë ˆì˜¤ ê¹Šì´ ê³„ì‚° (253 lines)
â”œâ”€â”€ checkpoints/              # ğŸ’¾ í›ˆë ¨ëœ ëª¨ë¸ë“¤
â”œâ”€â”€ logs/                     # ğŸ“Š í…ì„œë³´ë“œ ë¡œê·¸
â”œâ”€â”€ data/                     # ğŸ“ ë°ì´í„°ì…‹
â”œâ”€â”€ requirements.txt          # ğŸ“¦ ì˜ì¡´ì„± ëª©ë¡
â””â”€â”€ README.md                 # ğŸ“– ì´ ë¬¸ì„œ
```

## ğŸ¯ ëª¨ë¸ ì•„í‚¤í…ì²˜

### ThreeTaskDSPNet êµ¬ì¡°
```
ì…ë ¥ ì´ë¯¸ì§€ (3Ã—512Ã—512)
         â†“
   DSPNetBackbone (ResNet-50)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ C3: 512Ã—64Ã—64          â”‚
   â”‚ C4: 1024Ã—32Ã—32         â”‚  
   â”‚ C5: 2048Ã—16Ã—16         â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Detection   â”‚ Surface     â”‚ Depth       â”‚
â”‚ Head (SSD)  â”‚ Head (FCN)  â”‚ Head (FCN)  â”‚
â”‚             â”‚             â”‚             â”‚
â”‚ 7-level     â”‚ Pyramid     â”‚ Simple      â”‚
â”‚ pyramid     â”‚ pooling     â”‚ upsampling  â”‚
â”‚ 22,516      â”‚ 7 classes   â”‚ Pixel-wise  â”‚
â”‚ anchors     â”‚ 512Ã—512     â”‚ regression  â”‚
â”‚ 29+1 cls    â”‚ output      â”‚ 512Ã—512     â”‚
â”‚ + bbox(4)   â”‚             â”‚ output      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“Š ë°ì´í„° ì²˜ë¦¬ í˜„í™©

#### Detection ë°ì´í„°
- **29ê°œ í´ë˜ìŠ¤**: ì‹¤ì œ ì¥ì• ë¬¼ íƒ€ì… (1-29 range)
- **ì™„ë²½í•œ ë¶„ë¦¬**: `[x1, y1, x2, y2, class]` â†’ bbox(4D) + labels(1D)
- **SSD ì•µì»¤**: 22,516ê°œ ì•µì»¤ ë°•ìŠ¤ ìƒì„±
- **IoU ë§¤ì¹­**: 0.5 threshold positive, 0.4 threshold negative

#### Surface ë°ì´í„°
- **46,352ê°œ ìƒ˜í”Œ**: 394ê°œ Surface í´ë”ì—ì„œ ë¡œë“œ
- **7ê°œ í´ë˜ìŠ¤**: ë°°ê²½ í¬í•¨ í‘œë©´ ë¶„í• 
- **ì™„ë²½í•œ ë§ˆìŠ¤í¬**: XML ë¼ë²¨ê³¼ MASK í´ë” ì—°ë™

#### Depth ë°ì´í„°
- **15,807ê°œ ìƒ˜í”Œ**: 24ê°œ Depth í´ë”ì—ì„œ ë¡œë“œ
- **ìŠ¤í…Œë ˆì˜¤ ì²˜ë¦¬**: Left + Disp16 + Confidence
- **256 ìŠ¤ì¼€ì¼**: ì¼ê´€ëœ depth ê°’ ì²˜ë¦¬

## ğŸ”§ í•µì‹¬ ì»´í¬ë„ŒíŠ¸

### 1. **ThreeTaskDSPNet** (`src/model.py`)
```python
class ThreeTaskDSPNet(nn.Module):
    """3íƒœìŠ¤í¬ í†µí•© ëª¨ë¸"""
    
    def forward(self, x):
        features = self.backbone(x)
        
        # Detection: SSD ë°©ì‹
        detection_cls, detection_reg = self.detection_head(*features)
        
        # Surface: FCN + Pyramid Pooling
        surface_segmentation = self.surface_head(*features)
        
        # Depth: ë‹¨ìˆœ upsampling
        depth_estimation = self.depth_head(features[-1])
        
        return {
            'detection_cls': detection_cls,    # (B, 22516, 30)
            'detection_reg': detection_reg,    # (B, 22516, 4)
            'surface_segmentation': surface_segmentation,  # (B, 7, 512, 512)
            'depth_estimation': depth_estimation,  # (B, 1, 512, 512)
            'anchors': self._anchors
        }
```

### 2. **ë°ì´í„° ë¶„ë¦¬ ì‹œìŠ¤í…œ** (`utils/dataset.py`)
```python
def collate_fn(batch):
    """SSD êµ¬ì¡°ì— ë§ëŠ” ë°ì´í„° ë¶„ë¦¬"""
    
    for item in batch:
        if 'boxes' in item:
            boxes_data = item['boxes']  # (N, 5) - [x1, y1, x2, y2, class]
            
            # bboxì™€ í´ë˜ìŠ¤ ë¶„ë¦¬
            bbox_coords = boxes_data[:, :4]  # (N, 4)
            labels = boxes_data[:, 4].long()  # (N,)
            
            detection_boxes.append(bbox_coords)
            detection_labels.append(labels)
```

### 3. **IoU ê¸°ë°˜ ì•µì»¤ ë§¤ì¹­** (`src/losses.py`)
```python
def iou_match_anchors_with_labels(gt_boxes, anchors):
    """ì‹¤ì œ í´ë˜ìŠ¤ ë¼ë²¨ í¬í•¨ IoU ë§¤ì¹­"""
    
    # IoU ê³„ì‚°
    ious = compute_iou(gt_boxes[:, :4], anchors)
    
    # 3ë‹¨ê³„ ë¶„ë¥˜
    positive_mask = best_ious >= 0.5
    negative_mask = best_ious < 0.4
    ignore_mask = ~(positive_mask | negative_mask)  # 0.4 â‰¤ IoU < 0.5
    
    # ì‹¤ì œ í´ë˜ìŠ¤ ë¼ë²¨ í• ë‹¹
    matched_labels[positive_mask] = gt_labels[best_gt_indices[positive_mask]]
    matched_labels[negative_mask] = 0  # background
    matched_labels[ignore_mask] = -1   # ignore
```

### 4. **FocalLoss with Ignore** (`src/losses.py`)
```python
class FocalLoss(nn.Module):
    def __init__(self, alpha=0.25, gamma=2.0, ignore_index=-1):
        # Cross-entropy with ignore_index=-1
        ce_loss = F.cross_entropy(inputs, targets, 
                                 reduction='none', ignore_index=-1)
        
        # Apply focal loss weights only to valid samples
        valid_mask = (targets != -1)
        if valid_mask.sum() == 0:
            return torch.tensor(0.0, device=inputs.device, requires_grad=True)
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. í™˜ê²½ ì„¤ì •
```bash
# ê°€ìƒí™˜ê²½ ìƒì„± (ê¶Œì¥)
python -m venv .venv
source .venv/bin/activate  # Linux/Mac

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt
```

#### ğŸ“¦ ì£¼ìš” ì˜ì¡´ì„±
```bash
# í•µì‹¬ í”„ë ˆì„ì›Œí¬
torch>=2.0.0              # PyTorch ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬
torchvision>=0.15.0        # ì»´í“¨í„° ë¹„ì „ ìœ í‹¸ë¦¬í‹°
tensorboard>=2.10.0        # í›ˆë ¨ ëª¨ë‹ˆí„°ë§

# ì»´í“¨í„° ë¹„ì „
opencv-python>=4.5.0       # ì´ë¯¸ì§€ ì²˜ë¦¬
Pillow>=9.0.0             # ì´ë¯¸ì§€ I/O
scikit-image>=0.19.0      # ê³ ê¸‰ ì´ë¯¸ì§€ ì²˜ë¦¬

# ë°ì´í„° ë¶„ì„
numpy>=1.22.0             # ìˆ˜ì¹˜ ê³„ì‚°
scipy>=1.8.0              # ê³¼í•™ ê³„ì‚°
scikit-learn>=1.1.0       # ë¨¸ì‹ ëŸ¬ë‹ ìœ í‹¸ë¦¬í‹°

# ì‹œê°í™”
matplotlib>=3.5.0         # í”Œë¡¯ ë° ê·¸ë˜í”„
seaborn>=0.11.0          # í†µê³„ ì‹œê°í™”

# ìœ í‹¸ë¦¬í‹°
tqdm>=4.64.0              # ì§„í–‰ë¥  í‘œì‹œ
```

#### ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­
- **Python**: >= 3.8 (ê¶Œì¥: 3.9+)
- **CUDA**: >= 11.0 (GPU ì‚¬ìš©ì‹œ)
- **ë©”ëª¨ë¦¬**: ìµœì†Œ 8GB RAM, ê¶Œì¥ 16GB+
- **GPU ë©”ëª¨ë¦¬**: ìµœì†Œ 4GB VRAM ê¶Œì¥

### 2. ë°ì´í„° ì¤€ë¹„
```bash
# ë°ì´í„°ì…‹ êµ¬ì¡°
data/original_dataset/
â”œâ”€â”€ bbox/                      # Detection ë°ì´í„°
â”‚   â””â”€â”€ [394ê°œ í´ë”]/
â”‚       â”œâ”€â”€ *.jpg             # ì´ë¯¸ì§€ íŒŒì¼ë“¤
â”‚       â””â”€â”€ *.xml             # CVAT í˜•ì‹ ë¼ë²¨
â”œâ”€â”€ surface/                   # Surface ë°ì´í„°  
â”‚   â””â”€â”€ [394ê°œ í´ë”]/
â”‚       â”œâ”€â”€ *.jpg             # ì´ë¯¸ì§€ íŒŒì¼ë“¤
â”‚       â””â”€â”€ MASK/
â”‚           â””â”€â”€ *.png         # ë§ˆìŠ¤í¬ íŒŒì¼ë“¤
â””â”€â”€ depth/                     # Depth ë°ì´í„°
    â””â”€â”€ [24ê°œ í´ë”]/
        â”œâ”€â”€ left_image/       # ì¢Œì¸¡ ì¹´ë©”ë¼ ì´ë¯¸ì§€
        â”œâ”€â”€ disp16/          # Disparity ë§µ
        â””â”€â”€ confidence/       # ì‹ ë¢°ë„ ë§µ
```

### 3. í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸
```bash
# ëª¨ë¸-ë°ì´í„° í˜¸í™˜ì„± í™•ì¸
python -c "
from utils.dataset import ThreeTaskDataset, collate_fn
from src.model import ThreeTaskDSPNet
from src.losses import SimpleTwoTaskLoss
from torch.utils.data import DataLoader

# ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸
dataset = ThreeTaskDataset(max_samples=6)
dataloader = DataLoader(dataset, batch_size=2, collate_fn=collate_fn)

# ëª¨ë¸ ë° Loss í…ŒìŠ¤íŠ¸  
model = ThreeTaskDSPNet()
loss_fn = SimpleTwoTaskLoss()

for batch in dataloader:
    outputs = model(batch['images'])
    loss, losses = loss_fn(outputs, batch)
    print(f'âœ… í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸ ì„±ê³µ: Loss = {loss.item():.4f}')
    break
"
```

### 4. í›ˆë ¨ ì‹¤í–‰
```bash
# ê¸°ë³¸ í›ˆë ¨ (3íƒœìŠ¤í¬)
python scripts/train.py

# ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (100 ìƒ˜í”Œ, 5 ì—í­)
python scripts/train.py --config quick_test

# ëŒ€ìš©ëŸ‰ í›ˆë ¨ (ì „ì²´ ë°ì´í„°)
python scripts/train.py --config massive_dataset --epochs 100
```

### 5. ê²°ê³¼ í™•ì¸
```bash
# ëª¨ë¸ í…ŒìŠ¤íŠ¸
python scripts/test.py -c checkpoints/best_model.pth -i test_image.jpg

# í…ì„œë³´ë“œ ëª¨ë‹ˆí„°ë§
tensorboard --logdir logs/
```

## âš™ï¸ ì„¤ì • ì‹œìŠ¤í…œ

ì¤‘ì•™í™”ëœ ì„¤ì • ê´€ë¦¬ë¡œ ì‰¬ìš´ ì‹¤í—˜:

```python
from configs import Config, get_quick_test_config, get_massive_dataset_config

# ê¸°ë³¸ ì„¤ì • (3íƒœìŠ¤í¬)
config = Config()

# ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©
config = get_quick_test_config()  # 100 ìƒ˜í”Œ, 5 ì—í­

# ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ìš©  
config = get_massive_dataset_config()  # ì „ì²´ ë°ì´í„°, 100 ì—í­

# ì„¤ì • í™•ì¸
config.print_config()
```

### ì£¼ìš” ì„¤ì •

#### ModelConfig
```python
num_detection_classes: 29      # ì¥ì• ë¬¼ í´ë˜ìŠ¤
num_surface_classes: 7         # í‘œë©´ í´ë˜ìŠ¤ (ë°°ê²½ í¬í•¨)
input_size: (512, 512)         # ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°
pretrained_backbone: True      # ResNet-50 ì‚¬ì „í›ˆë ¨ ê°€ì¤‘ì¹˜
```

#### TrainingConfig
```python
epochs: 50                     # í›ˆë ¨ ì—í­
batch_size: 4                  # ë°°ì¹˜ í¬ê¸°
learning_rate: 1e-4            # í•™ìŠµë¥ 
detection_weight: 1.0          # Detection loss ê°€ì¤‘ì¹˜
surface_weight: 1.0            # Surface loss ê°€ì¤‘ì¹˜
```

#### DataConfig
```python
max_samples: 2000              # ìµœëŒ€ ìƒ˜í”Œ ìˆ˜
train_ratio: 0.8               # í›ˆë ¨/ê²€ì¦ ë¶„í•  ë¹„ìœ¨
base_dir: "data/original_dataset"  # ë°ì´í„° ê²½ë¡œ
```

## ğŸ“Š ì„±ëŠ¥ ë° ê²°ê³¼

### ë°ì´í„° ë¡œë”© ì„±ëŠ¥
- **Detection**: ğŸ“Š ì •í™•í•œ ìƒ˜í”Œ ìˆ˜ (XML íŒŒì‹± ê¸°ë°˜)
- **Surface**: 46,352ê°œ ìƒ˜í”Œ (394ê°œ í´ë”)  
- **Depth**: 15,807ê°œ ìƒ˜í”Œ (24ê°œ í´ë”)
- **ì „ì²´**: 62,159ê°œ ìƒ˜í”Œ ì„±ê³µì  ë¡œë”©

### ëª¨ë¸ ì¶œë ¥ ê²€ì¦
```
âœ… Detection Classification: (2, 22516, 30) - 30ê°œ í´ë˜ìŠ¤ (29 + background)
âœ… Detection Regression: (2, 22516, 4) - 4ì°¨ì› bbox ì¢Œí‘œ
âœ… Surface Segmentation: (2, 7, 512, 512) - 7ê°œ í´ë˜ìŠ¤ ë¶„í• 
âœ… Depth Estimation: (2, 1, 512, 512) - í”½ì…€ë³„ ê¹Šì´ ê°’
```

### Loss ê³„ì‚° ì„±ê³µ
```
âœ… Total Loss: 10.2813
   - cls_loss: 10.2479 (Classification)
   - bbox_loss: 0.0334 (Regression)
   - surface_loss: ê³„ì‚°ë¨
   - depth_loss: ê³„ì‚°ë¨
```

## ğŸ”¬ ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­

### SSD ì•µì»¤ êµ¬ì¡°
```python
Feature scales: [8, 16, 32, 64, 128, 256, 512]
Anchors per location: [4, 4, 6, 6, 6, 4, 4]
Total levels: 7

Level 0: (64, 64) -> 16,384 anchors
Level 1: (32, 32) -> 4,096 anchors  
Level 2: (16, 16) -> 1,536 anchors
Level 3: (8, 8) -> 384 anchors
Level 4: (4, 4) -> 96 anchors
Level 5: (2, 2) -> 16 anchors
Level 6: (1, 1) -> 4 anchors

âœ… Total anchors: 22,516ê°œ
```

### IoU ê¸°ë°˜ ë§¤ì¹­ ì „ëµ
- **Positive**: IoU â‰¥ 0.5 (ì‹¤ì œ í´ë˜ìŠ¤ í• ë‹¹)
- **Negative**: IoU < 0.4 (ë°°ê²½ í´ë˜ìŠ¤)  
- **Ignore**: 0.4 â‰¤ IoU < 0.5 (ë¬´ì‹œ, -1 ë¼ë²¨)
- **Hard Negative Mining**: 3:1 ë¹„ìœ¨

### ë°ì´í„° ì „ì²˜ë¦¬
- **ì´ë¯¸ì§€**: 512Ã—512 ë¦¬ì‚¬ì´ì¦ˆ + ImageNet ì •ê·œí™”
- **Detection**: bbox ì¢Œí‘œ ì •ê·œí™” + í´ë˜ìŠ¤ ë¶„ë¦¬
- **Surface**: ë§ˆìŠ¤í¬ ë‹¤ìš´ìƒ˜í”Œë§
- **Depth**: 256 ìŠ¤ì¼€ì¼ ê³ ì • ì²˜ë¦¬

## ğŸ› ï¸ ê°œë°œ ë° ë””ë²„ê¹…

### ì£¼ìš” í•´ê²° ë¬¸ì œë“¤
1. **ì°¨ì› ë¶ˆì¼ì¹˜**: 5ì°¨ì› â†’ 4ì°¨ì› bbox ë¶„ë¦¬
2. **Target -1 ì²˜ë¦¬**: `ignore_index` ì¶”ê°€
3. **Distance ì œê±°**: ìˆœìˆ˜ Object Detection êµ¬ì¡°
4. **ì‹¤ì œ í´ë˜ìŠ¤**: 1-29 ë²”ìœ„ ì •í™•í•œ ë§¤í•‘
5. **Depth ìŠ¤ì¼€ì¼**: 256 ê³ ì •ìœ¼ë¡œ ì¼ê´€ì„± í™•ë³´

### í…ŒìŠ¤íŠ¸ ë° ê²€ì¦
```bash
# ê°„ë‹¨í•œ í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸
python -c "
from utils.dataset import ThreeTaskDataset
from src.model import ThreeTaskDSPNet

dataset = ThreeTaskDataset(max_samples=6)
model = ThreeTaskDSPNet()

print(f'âœ… Dataset: {len(dataset)} samples')
print(f'âœ… Model: {sum(p.numel() for p in model.parameters())} parameters')
"
```

## ğŸ“ˆ í–¥í›„ ê³„íš

### ë‹¨ê¸° ëª©í‘œ
- [ ] ì •í™•ë„ ë²¤ì¹˜ë§ˆí¬ ìˆ˜í–‰
- [ ] ì¶”ë¡  ì†ë„ ìµœì í™”
- [ ] TensorRT ë³€í™˜ ì§€ì›
- [ ] Docker ì»¨í…Œì´ë„ˆí™”

### ì¤‘ê¸° ëª©í‘œ  
- [ ] ì‹¤ì‹œê°„ ë¹„ë””ì˜¤ ì²˜ë¦¬
- [ ] ëª¨ë°”ì¼ ë””ë°”ì´ìŠ¤ í¬íŒ…
- [ ] Edge ë””ë°”ì´ìŠ¤ ìµœì í™”
- [ ] ë‹¤ì–‘í•œ ë„ì‹œ í™˜ê²½ ë°ì´í„° í™•ì¥

### ì¥ê¸° ëª©í‘œ
- [ ] ììœ¨ì£¼í–‰ì°¨ í†µí•©
- [ ] ë¡œë´‡ ë‚´ë¹„ê²Œì´ì…˜ í™œìš©
- [ ] AR/VR ì‘ìš© ê°œë°œ

## ğŸ¤ ê¸°ì—¬ ë°©ë²•

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ë¥¼ ë”°ë¦…ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ `LICENSE` íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.

## ğŸ“ ë¬¸ì˜

í”„ë¡œì íŠ¸ì— ëŒ€í•œ ì§ˆë¬¸ì´ë‚˜ ì œì•ˆì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ Issueë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”.

---

**SafeStrp** - ì¸ë„ë³´í–‰ ì•ˆì „ì„ ìœ„í•œ ì°¨ì„¸ëŒ€ ì»´í“¨í„° ë¹„ì „ ì‹œìŠ¤í…œ ğŸš¶â€â™€ï¸ğŸ›¡ï¸